mysql {
  user = "hue_user"
  pwd = "hue_test"
  jdbc = "jdbc:mysql://10.31.73.48:3306/"
  db = "hue"
}


//kafka {
//  //  brokers = "10.11.159.85:6667,10.11.159.86:6667,10.11.159.87:6667,10.11.159.88:6667,10.11.159.89:6667,10.11.159.90:6667"
//  brokers = "10.31.96.221:9092,10.31.96.222:9092,10.31.96.223:9092,10.31.96.224:9092,10.31.96.225:9092,10.31.96.226:9092,10.31.96.227:9092,10.31.96.228:9092,10.31.96.229:9092,10.31.96.230:9092"
//  topics = "rdc_nginxlog"
//}

kafka {
  brokers = "10.31.96.221:9092"
  topics = "vr_event"
}

spark {
  batchinterval = 60 //seconds
}

redis{
  redisHost = "m.redis.sohucs.com"
  redisPort = 22132
  redisTimeout = 30000000
  redisPassWord = "61ce6d4984a4bbd3102c1205a78e5072"

}

log{
  logtype = 0 //日志类型，0不带cookie，1带cookie
}

hbase{
  namespaceTable = "cdn:realtimestat"
}

app{
  name = "Spark Streaming App"
  writegap = 3600 // seconds
}

dir{
  checkpoint = "/user/xiaoliu/checkpoint"
  output = "/user/xiaoliu/data_zxs" // HDFS output directory
}